---
title: "High Conflict Area Calculations"
author: "Mia Guarnieri"
date: "2023-03-01"
output: html_document
---

#Summary

This Rmd contains the instructions and code for calculating the area of high conflict (modeled conflict risk â‰¥ 0.7) within your modeled conflict rasters, once you have used the model to generate them.


# Load in necessary packages (and file path, if needed)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#reading in the required packages

library(tidyverse)
library(here)
library(terra)
library(sf)

#setting up a file path - useful if your data is being read in from a Google Drive, your desktop, or somewhere other than your designated working directory
gdrive_data <- "/Users/mia/Library/CloudStorage/GoogleDrive-mguarnieri@ucsb.edu/Shared drives/Black_Bear_Aware/gdrive_data"
```

# Visually test cutoffs for "high conflict"

```{r}
#load in your predicted conflict raster
proj_conf <- rast(here(gdrive_data, "/AnalysisData/model_outputs/projected_mod3_clim_map_squared.tif"))


#60 percent cutoff

conf_60perc <- proj_conf #assign your conflict raster to an object

conf_60perc[conf_60perc > 0.6] <- 1  #any pixel in this raster with a value greater than 0.6 will have a value of 1
conf_60perc[conf_60perc < 0.6] <- NA #any pixel with a value lower than 0.1 will have no value (NA)

poly_per60 <- as.polygons(conf_60perc, dissolve = TRUE) #convert the raster to a series of polygons for visualization

#70 percent cutoff; same process as above

conf_70perc <- proj_conf

conf_70perc[conf_70perc > 0.7] <- 1
conf_70perc[conf_70perc < 0.7] <- NA

poly_per70 <- as.polygons(conf_70perc, dissolve = TRUE)

#80 percent cutoff; same process as above

conf_80perc <- proj_conf

conf_80perc[conf_80perc > 0.8] <- 1
conf_80perc[conf_80perc < 0.8] <- NA

poly_per80 <- as.polygons(conf_80perc, dissolve = TRUE)

#90 percent cutoff; same process as above

conf_90perc <- proj_conf

conf_90perc[conf_90perc > 0.9] <- 1
conf_90perc[conf_90perc < 0.9] <- NA

poly_per90 <- as.polygons(conf_90perc, dissolve = TRUE)

#plot your polygons to see how they look visually

plot(poly_per60)
plot(poly_per70) #we selected a cutoff of 0.7 probability
plot(poly_per80)
plot(poly_per90)

```

#Create high conflict layer and vectorize it

Our high conflict layer will be created based on the cutoff determined by our visual analysis. We selected 0.7.

```{r}
#read in the desired conflict rasters (your model outputs)

current_conf <- rast(here(gdrive_data, "/AnalysisData/model_outputs/mod3clim_map_squared.tif"))

proj_conf <- rast(here(gdrive_data, "/AnalysisData/model_outputs/projected_mod3_clim_map_squared.tif"))

#reassign to be high conflict only

current_high <- current_conf #assign present-day conflict raster to new object

current_high[current_high > 0.7] <- 1 #0.7 and above = 1
current_high[current_high < 0.7] <- NA #anything below 0.7 = NA


proj_high <- proj_conf #assign projected (2030) conflict raster to a new object

proj_high[proj_high > 0.7] <- 1 #0.7 and above = 1
proj_high[proj_high < 0.7] <- NA #anything below 0.7 = NA

#save high conflict rasters for map creation and ease of analysis

writeRaster(current_high, filename = here(gdrive_data, "/AnalysisData/model_outputs/mod3sq_current_highconf.tif"), filetype = "GTiff", overwrite = TRUE)

writeRaster(proj_high, filename = here(gdrive_data, "/AnalysisData/model_outputs/mod3sq_projected_highconf.tif"), filetype = "GTiff", overwrite = TRUE)


#to make these into a shapefile - vectorize and convert to sf object type

current_high_pols <- as.polygons(current_high, dissolve = TRUE) %>% #turn raster into polygons, merging adjacent ones
  st_as_sf() #convert to an sf object (can be safed as a shapefile)

projected_high_pols <- as.polygons(proj_high, dissolve = TRUE) %>% 
  st_as_sf()

#save your new shapefiles using the st_write() function

st_write(current_high_pols, dsn = here(gdrive_data, "/AnalysisData/model_outputs/shapefiles/mod3sq_current_highconf.shp"))

st_write(projected_high_pols, dsn = here(gdrive_data, "/AnalysisData/model_outputs/shapefiles/mod3sq_projected_highconf.shp"))

```

#Determine how much high conflict area is within each administrative boundary

```{r}

#read in CDFW regions

#read in the CDFW regions shapefile
cdfw_regions <- read_sf(here(gdrive_data, "/IntermediateData/IntermediateData_Files/cdfw_regions_reproj/cdfw_regions.shp"))

cdfw_regions_vect <- cdfw_regions %>%
  select(REGION, geometry) %>% #keep only the region names and geometries
  vect() #convert to a spatvector for analysis

#read in CA counties

#read in the shapefile
ca_county <- read_sf(here(gdrive_data, "/InputData/InputData_Files/geoportal_ca_counties/cnty19_1.shp")) %>% 
  st_transform(crs = crs(cdfw_regions)) #match the crs to that of the regions shapefile

ca_county_vect <- ca_county %>% 
  select(COUNTY_NAM, geometry) %>% #keep only county names and geometries
  vect() #convert to a spatvector

#read in high conflict rasters (you saved these earlier)

current_highconf_raster <- rast(here(gdrive_data, "/AnalysisData/model_outputs/mod3sq_current_highconf.tif"))

projected_highconf_raster <- rast(here(gdrive_data, "/AnalysisData/model_outputs/mod3sq_projected_highconf.tif"))


#find CDFW administrative regions with largest area of high conflict

#extract the sum of the pixel values within each cdfw region - since pixels have a value of 1 each, this will give a count of the pixels
current_regional_conf <- extract(current_highconf_raster, cdfw_regions_vect, na.rm = TRUE, fun = "sum")

#create a new column that multiplies the count of pixels by the area per pixel (in our case, that is 52943.53 square meters) to get total area of high conflict within that region
regional_summary_current <- current_regional_conf %>%
  mutate(area = lyr1 * 52943.53)

#repeat these steps for the projected map
projected_regional_conf <- extract(projected_highconf_raster, cdfw_regions_vect, na.rm = TRUE, fun = "sum")

regional_summary_projected <- projected_regional_conf %>% 
  mutate(area = lyr1 * 52943.53)

#find counties with the most area of high conflict

#current day
current_county_conf <- extract(current_highconf_raster, ca_county_vect, na.rm = TRUE, fun = "sum") #extract count

county_summary_current <- current_county_conf %>%
  mutate(area = lyr1 * 52943.53) #multiply pixel count by area per cell

#NEW STEP - rename the columns in the extracted data frame to have an "OBJECTID" column for merging with county shapefile; only necessary if you plan to map your results
colnames(county_summary_current) <- c("OBJECTID", "cells", "area")

#join the data frame to the county shapefile to have both geometry and area of high conflict in one file
current_countysumm <- full_join(county_summary_current, ca_county, by = "OBJECTID")

#projected
projected_county_conf <- extract(projected_highconf_raster, ca_county_vect, na.rm = TRUE, fun = "sum")

county_summary_projected <- projected_county_conf %>%
  mutate(area = lyr1 * 52943.53) #multiply cell count by area per cell

colnames(county_summary_projected) <- c("OBJECTID", "cells", "area") #rename columns

projected_countysumm <- full_join(county_summary_projected, ca_county, by = "OBJECTID") #merge with shapefile

#save county summary shps that you created with the full_join function
st_write(current_countysumm, dsn = here(gdrive_data, "/AnalysisData/model_outputs/shapefiles/county_stats/current_county_highconf.shp"))

st_write(projected_countysumm, dsn = here(gdrive_data, "/AnalysisData/model_outputs/shapefiles/county_stats/projected_county_highconf.shp"))

```

#Filter current day for only 0 values and projected for nonzero values - THIS SECTION COMING OUT FOR PUBLIC-FACING FILES BUT KEPT IN ORIGINAL REPO

```{r}
#read in current raster and keep only the lowest decile

current_conf <- rast(here(gdrive_data, "/AnalysisData/model_outputs/mod3clim_map_squared.tif"))

decs_current <- global(current_conf, quantile, probs = seq(0, 1, 0.1), na.rm = TRUE)

current_zeros <- current_conf #assign conflict raster to new object

current_zeros[current_zeros > 0.01] <- NA #anything greater than 1 percent

#read in projected raster and keep only top 50%

proj_conf <- rast(here(gdrive_data, "/AnalysisData/model_outputs/projected_mod3_clim_map_squared.tif"))

proj_nonzero <- proj_conf

proj_nonzero[proj_nonzero < 0.5] <- NA #set anything lower than  50% to NA
proj_nonzero[proj_nonzero > 0.5] <- 1 #and anything higher to 1 
```

#Mask and take the difference - THIS SECTION COMING OUT FOR PUBLIC-FACING FILES BUT KEPT IN ORIGINAL REPO

```{r}
#CA counties

ca_county <- read_sf(here(gdrive_data, "/InputData/InputData_Files/geoportal_ca_counties/cnty19_1.shp")) %>% 
  st_transform(crs = crs(cdfw_regions))

ca_county_vect <- ca_county %>% 
  select(COUNTY_NAM, geometry) %>% 
  vect()

# mask it - keep only zeros that will be in the top 50

masked_proj_nonzero <- mask(current_zeros, proj_nonzero)


plot(proj_nonzero_change)

#extract # of cells by county
projected_county_nonzero_change <- extract(proj_nonzero_change, ca_county_vect, na.rm = TRUE, fun = "mean")

colnames(projected_county_nonzero_change) <- c("OBJECTID", "avg_conf")

projected_countysumm_nonzeros <- full_join(projected_county_nonzero_change, ca_county, by = "OBJECTID")

#export county summary shps
st_write(current_countysumm, dsn = here(gdrive_data, "/AnalysisData/model_outputs/shapefiles/county_stats/current_county_highconf.shp"))

```

