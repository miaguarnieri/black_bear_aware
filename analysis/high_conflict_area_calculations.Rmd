---
title: "High Conflict Area Calculations"
author: "Mia Guarnieri"
date: "2023-03-01"
output: html_document
---

#Summary

This Rmd contains the instructions and code for calculating the area of high conflict (modeled conflict risk â‰¥ 0.7) within your modeled conflict rasters, once you have used the model to generate them.


# Load in necessary packages (and file path, if needed)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#reading in the required packages

library(tidyverse)
library(here)
library(terra)
library(sf)

#setting up a file path - useful if your data is being read in from a Google Drive, your desktop, or somewhere other than your designated working directory
gdrive_data <- "/Users/mia/Library/CloudStorage/GoogleDrive-mguarnieri@ucsb.edu/Shared drives/Black_Bear_Aware/gdrive_data"
```

# Visually test cutoffs for "high conflict"

```{r}
#load in your predicted conflict raster
proj_conf <- rast(here(gdrive_data, "/AnalysisData/model_outputs/projected_mod3_clim_map_squared.tif"))


#60 percent cutoff

conf_60perc <- proj_conf #assign your conflict raster to an object

conf_60perc[conf_60perc > 0.6] <- 1  #any pixel in this raster with a value greater than 0.6 will have a value of 1
conf_60perc[conf_60perc < 0.6] <- NA #any pixel with a value lower than 0.1 will have no value (NA)

poly_per60 <- as.polygons(conf_60perc, dissolve = TRUE) #convert the raster to a series of polygons for visualization

#70 percent cutoff; same process as above

conf_70perc <- proj_conf

conf_70perc[conf_70perc > 0.7] <- 1
conf_70perc[conf_70perc < 0.7] <- NA

poly_per70 <- as.polygons(conf_70perc, dissolve = TRUE)

#80 percent cutoff; same process as above

conf_80perc <- proj_conf

conf_80perc[conf_80perc > 0.8] <- 1
conf_80perc[conf_80perc < 0.8] <- NA

poly_per80 <- as.polygons(conf_80perc, dissolve = TRUE)

#90 percent cutoff; same process as above

conf_90perc <- proj_conf

conf_90perc[conf_90perc > 0.9] <- 1
conf_90perc[conf_90perc < 0.9] <- NA

poly_per90 <- as.polygons(conf_90perc, dissolve = TRUE)

#plot your polygons to see how they look visually

plot(poly_per60)
plot(poly_per70) #we selected a cutoff of 0.7 probability
plot(poly_per80)
plot(poly_per90)

```

#Create high conflict layer and vectorize it

Our high conflict layer will be created based on the cutoff determined by our visual analysis. We selected 0.7.

```{r}
#read in the desired conflict rasters (your model outputs)

current_conf <- rast(here(gdrive_data, "/AnalysisData/model_outputs/mod3clim_map_squared.tif"))

proj_conf <- rast(here(gdrive_data, "/AnalysisData/model_outputs/projected_mod3_clim_map_squared.tif"))

#reassign to be high conflict only

current_high <- current_conf #assign present-day conflict raster to new object

current_high[current_high > 0.7] <- 1 #0.7 and above = 1
current_high[current_high < 0.7] <- NA #anything below 0.7 = NA


proj_high <- proj_conf #assign projected (2030) conflict raster to a new object

proj_high[proj_high > 0.7] <- 1 #0.7 and above = 1
proj_high[proj_high < 0.7] <- NA #anything below 0.7 = NA

#save high conflict rasters for map creation and ease of analysis

writeRaster(current_high, filename = here(gdrive_data, "/AnalysisData/model_outputs/mod3sq_current_highconf.tif"), filetype = "GTiff", overwrite = TRUE)

writeRaster(proj_high, filename = here(gdrive_data, "/AnalysisData/model_outputs/mod3sq_projected_highconf.tif"), filetype = "GTiff", overwrite = TRUE)


#to make these into a shapefile - vectorize and convert to sf object type

current_high_pols <- as.polygons(current_high, dissolve = TRUE) %>% #turn raster into polygons, merging adjacent ones
  st_as_sf() #convert to an sf object (can be safed as a shapefile)

projected_high_pols <- as.polygons(proj_high, dissolve = TRUE) %>% 
  st_as_sf()

#save your new shapefiles using the st_write() function

st_write(current_high_pols, dsn = here(gdrive_data, "/AnalysisData/model_outputs/shapefiles/mod3sq_current_highconf.shp"))

st_write(projected_high_pols, dsn = here(gdrive_data, "/AnalysisData/model_outputs/shapefiles/mod3sq_projected_highconf.shp"))

```

#Determine how much high conflict area is within each administrative boundary

First, read in the conflict rasters (they are used for all analyses)

```{r}
#read in high conflict rasters (you saved these earlier)

current_highconf_raster <- rast(here(gdrive_data, "/AnalysisData/model_outputs/mod3sq_current_highconf.tif"))

projected_highconf_raster <- rast(here(gdrive_data, "/AnalysisData/model_outputs/mod3sq_projected_highconf.tif"))
```

## California Department of Fish and Wildlife regions

```{r}
#read in the CDFW regions shapefile
cdfw_regions <- read_sf(here(gdrive_data, "/IntermediateData/IntermediateData_Files/cdfw_regions_reproj/cdfw_regions.shp"))

#select for only regions and geometry and convert to a spatvector object
cdfw_regions_vect <- cdfw_regions %>%
  select(REGION, geometry) %>% #keep only the region names and geometries
  vect() #convert to a spatvector for analysis

#find CDFW administrative regions with largest area of high conflict

#extract the sum of the pixel values within each cdfw region - since pixels have a value of 1 each, this will give a count of the pixels
current_regional_conf <- extract(current_highconf_raster, cdfw_regions_vect, na.rm = TRUE, fun = "sum")

#create a new column that multiplies the count of pixels by the area per pixel (in our case, that is 52943.53 square meters) to get total area of high conflict within that region
regional_summary_current <- current_regional_conf %>%
  mutate(area = lyr1 * 52943.53)

#repeat these steps for the projected conflict risk raster
projected_regional_conf <- extract(projected_highconf_raster, cdfw_regions_vect, na.rm = TRUE, fun = "sum")

regional_summary_projected <- projected_regional_conf %>% 
  mutate(area = lyr1 * 52943.53)
```

## California counties

```{r}
#read in the CA counties shapefile
ca_county <- read_sf(here(gdrive_data, "/InputData/InputData_Files/geoportal_ca_counties/cnty19_1.shp")) %>% 
  st_transform(crs = crs(cdfw_regions)) #match the crs to that of the regions shapefile

ca_county_vect <- ca_county %>% 
  select(COUNTY_NAM, geometry) %>% #keep only county names and geometries
  vect() #convert to a spatvector

#find counties with the most area of high conflict

#current day
current_county_conf <- extract(current_highconf_raster, ca_county_vect, na.rm = TRUE, fun = "sum") #extract count

county_summary_current <- current_county_conf %>%
  mutate(area = lyr1 * 52943.53) #multiply pixel count by area per cell


# extra steps below are done if you would like to work with this information geospatially (in a shapefile)

#rename the columns in the extracted data frame to have an "OBJECTID" column for merging with county shapefile; only necessary if you plan to map your results
colnames(county_summary_current) <- c("OBJECTID", "cells", "area")

#join the data frame to the county shapefile to have both geometry and area of high conflict in one file
current_countysumm <- full_join(county_summary_current, ca_county, by = "OBJECTID")

#repeat the steps above for the projected conflict risk raster
projected_county_conf <- extract(projected_highconf_raster, ca_county_vect, na.rm = TRUE, fun = "sum")

county_summary_projected <- projected_county_conf %>%
  mutate(area = lyr1 * 52943.53) #multiply cell count by area per cell

colnames(county_summary_projected) <- c("OBJECTID", "cells", "area") #rename columns

projected_countysumm <- full_join(county_summary_projected, ca_county, by = "OBJECTID") #merge with shapefile


#save county summary shps that you created with the full_join function
st_write(current_countysumm, dsn = here(gdrive_data, "/AnalysisData/model_outputs/shapefiles/county_stats/current_county_highconf.shp"))

st_write(projected_countysumm, dsn = here(gdrive_data, "/AnalysisData/model_outputs/shapefiles/county_stats/projected_county_highconf.shp"))
```

